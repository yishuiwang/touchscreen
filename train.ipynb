{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File touch_trajectory_1732895380277.csv has only 3 data points and will be ignored.\n",
      "File touch_trajectory_1732895386207.csv has only 4 data points and will be ignored.\n",
      "File touch_trajectory_1732895357723.csv has only 4 data points and will be ignored.\n",
      "Number of valid files: 19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设置数据目录和过滤阈值\n",
    "data_dir = 'right_data'\n",
    "min_data_points = 5  # 最小数据点数量\n",
    "\n",
    "# 获取所有 CSV 文件\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# 过滤并加载数据\n",
    "filtered_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 检查数据点数量\n",
    "    if len(data) >= min_data_points:\n",
    "        filtered_data.append(data)\n",
    "    else:\n",
    "        print(f\"File {file} has only {len(data)} data points and will be ignored.\")\n",
    "\n",
    "# 检查过滤后的数据\n",
    "print(f\"Number of valid files: {len(filtered_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "for data in filtered_data:\n",
    "    # 计算长度\n",
    "    distances = np.sqrt(np.diff(data['x'])**2 + np.diff(data['y'])**2)\n",
    "    length = np.sum(distances)\n",
    "    \n",
    "\n",
    "    # 计算速度\n",
    "    begin = data['timestamp'].iloc[0]\n",
    "    end = data['timestamp'].iloc[-1]\n",
    "    duration = (end - begin)/1000\n",
    "    speed = length / duration\n",
    "\n",
    "    # 计算位移\n",
    "    displacement = np.sqrt((data['x'].iloc[-1] - data['x'].iloc[0])**2 + (data['y'].iloc[-1] - data['y'].iloc[0])**2)\n",
    "\n",
    "    # 计算弧度\n",
    "    angle = np.arctan2(data['y'].iloc[-1] - data['y'].iloc[0], data['x'].iloc[-1] - data['x'].iloc[0])\n",
    "\n",
    "    processed_data.append([length, speed, displacement, angle])\n",
    "\n",
    "\n",
    "features = np.array(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 3.3941357002986905\n",
      "Epoch 2, loss: 0.0002882396802306175\n",
      "Epoch 3, loss: 4.023473593406379e-05\n",
      "Epoch 4, loss: 3.5346787626622245e-05\n",
      "Epoch 5, loss: 3.439304782659747e-05\n",
      "Epoch 6, loss: 3.337969974381849e-05\n",
      "Epoch 7, loss: 3.3081654692068696e-05\n",
      "Epoch 8, loss: 3.248557186452672e-05\n",
      "Epoch 9, loss: 3.206831024726853e-05\n",
      "Epoch 10, loss: 3.177026883349754e-05\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "Accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 将数据转换为 PyTorch 张量\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "dataset = TensorDataset(features)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "# 定义模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)  #左手、右手\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs = data[0]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # 创建标签，右手为1\n",
    "        labels = torch.ones(inputs.size(0), 2, dtype=torch.float32)  # 调整标签形状以匹配输出\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, loss: {running_loss}\")\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data[0]\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "\n",
    "        total += inputs.size(0)\n",
    "        correct += (predicted == 1).sum().item()\n",
    "    \n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
